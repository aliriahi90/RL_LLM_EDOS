{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd95532-89f0-4598-9ae3-65be85af7dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3398, dev:486, test:970\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from tqdm import tqdm\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "df = pd.read_csv(\"edos_labelled_aggregated.csv\")\n",
    "df = df[df['label_vector'] != 'none']\n",
    "\n",
    "\n",
    "train_df, dev_df, test_df = df[df['split'] == 'train'], df[df['split'] == 'dev'], df[df['split'] == 'test']\n",
    "\n",
    "print(f\"train: {train_df.shape[0]}, dev:{dev_df.shape[0]}, test:{test_df.shape[0]}\")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = \"\"\"Fine-grained Vector of Sexism: for posts which are sexist, an 11-class classification where systems have to predict one of 11 fine-grained vectors.\n",
    "\n",
    "Given a post determine the post is belong to which class:\n",
    "1.1 threats of harm\n",
    "1.2 incitement and encouragement of harm\n",
    "2.1 descriptive attacks\n",
    "2.2 aggressive and emotive attacks\n",
    "2.3 dehumanising attacks & overt sexual objectification\n",
    "3.1 casual use of gendered slurs, profanities, and insults\n",
    "3.2 immutable gender differences and gender stereotypes\n",
    "3.3 backhanded gendered compliments\n",
    "3.4 condescending explanations or unwelcome advice\n",
    "4.1 supporting mistreatment of individual women\n",
    "4.2 supporting systemic discrimination against women as a group\n",
    "\n",
    "### Post: \n",
    "{POST}\n",
    "### Class: \"\"\"\n",
    "\n",
    "column='label_vector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd829bbe-1bc6-49a7-987a-adb219ee324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5eddaa3980948158b134c295c784a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_path = \"task_c_llm\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_path, padding_side=\"left\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load model with 4-bit precision\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(llm_path, quantization_config=quant_config, device_map={\"\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25c59c02-d657-4118-80f1-53aac35dea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tokenizer.encode(\"1. threats, plans to harm and incitement\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "005f83ef-3e53-4b2e-a5a3-9ddaef20839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class EDOSDataset(Dataset):\n",
    "    def __init__(self, df, prompt_template, column):\n",
    "        self.texts = df['text'].tolist()\n",
    "        self.labels = df[column].tolist()\n",
    "        self.prompt_template=prompt_template\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idxs):\n",
    "        inputs, inputs_labels = [], []\n",
    "        for idx in idxs:\n",
    "            \n",
    "            inputs.append(self.prompt_template.replace(\"{POST}\", self.texts[idx]))\n",
    "            inputs_labels.append(self.labels[idx])\n",
    "        \n",
    "        return {\"inputs\":inputs, \"labels\": inputs_labels}\n",
    "    \n",
    "def make_the_generations(model, tokenizer, data_loader):\n",
    "    gen_texts, labels = [], []\n",
    "    \n",
    "    for batch in tqdm(data_loader):\n",
    "        input_data = batch['inputs']\n",
    "        labels += batch['labels']\n",
    "        tokenized_input_data = tokenizer(input_data, padding=True, max_length=512, truncation=True, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "        # print(tokenized_input_data)\n",
    "        outputs = finetuned_model.generate(\n",
    "            **tokenized_input_data,\n",
    "            pad_token_id= tokenizer.eos_token_id,\n",
    "            max_new_tokens=20,\n",
    "            do_sample=True\n",
    "        )\n",
    "        generated_texts = [tokenizer.decode(outputs[idx], skip_special_tokens=True)[len(input_data[idx]):]\n",
    "                          for idx in range(len(outputs))]\n",
    "        gen_texts += generated_texts\n",
    "    return gen_texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "320b01d5-0ba0-453e-83b4-fb7709b93aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [01:57<00:00,  2.17s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_data = EDOSDataset(df=train_df, prompt_template=prompt_template, column=column)\n",
    "train_dataloader =  DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "train_texts, train_labels = make_the_generations(finetuned_model, tokenizer, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb597ed0-0967-435b-8cba-403ccd339647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:17<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "dev_data = EDOSDataset(df=dev_df, prompt_template=prompt_template, column=column)\n",
    "dev_dataloader =  DataLoader(dev_data, batch_size=batch_size, shuffle=False)\n",
    "dev_texts, dev_labels = make_the_generations(finetuned_model, tokenizer, dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e0d642a-188d-4498-8f8d-d3c922f2f79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:33<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "test_data = EDOSDataset(df=test_df, prompt_template=prompt_template, column=column)\n",
    "test_dataloader =  DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "test_texts, test_labels = make_the_generations(finetuned_model, tokenizer, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b931fa12-cd31-4d61-b61b-30b692bc0d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Vectorizer&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;count-vec&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              4))),\n",
       "                                                (&#x27;tfidf&#x27;,\n",
       "                                                 TfidfVectorizer(ngram_range=(1,\n",
       "                                                                              5),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                (&#x27;Classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Vectorizer&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;count-vec&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              4))),\n",
       "                                                (&#x27;tfidf&#x27;,\n",
       "                                                 TfidfVectorizer(ngram_range=(1,\n",
       "                                                                              5),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                (&#x27;Classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Vectorizer: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;count-vec&#x27;,\n",
       "                                CountVectorizer(ngram_range=(1, 4))),\n",
       "                               (&#x27;tfidf&#x27;,\n",
       "                                TfidfVectorizer(ngram_range=(1, 5),\n",
       "                                                sublinear_tf=True))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>count-vec</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 4))</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>tfidf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 5), sublinear_tf=True)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Vectorizer',\n",
       "                 FeatureUnion(transformer_list=[('count-vec',\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              4))),\n",
       "                                                ('tfidf',\n",
       "                                                 TfidfVectorizer(ngram_range=(1,\n",
       "                                                                              5),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                ('Classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV, LogisticRegressionCV, ElasticNetCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "vectorizer_1 = CountVectorizer(ngram_range=(1,4), lowercase=True)\n",
    "vectorizer_2 = TfidfVectorizer( ngram_range=(1,5), \n",
    "                                     lowercase=True, \n",
    "                                     sublinear_tf=True, \n",
    "                                     use_idf=True)\n",
    "features = FeatureUnion([\n",
    "    (\"count-vec\", vectorizer_1),\n",
    "    (\"tfidf\", vectorizer_2),\n",
    "])\n",
    "\n",
    "class_mapper = Pipeline (\n",
    "    steps=[\n",
    "        (\"Vectorizer\", features),\n",
    "        # (\"TruncatedSVD\", TruncatedSVD(n_components=600)),\n",
    "        ('Classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# class_mapper.fit(train_texts+train_labels+dev_texts, train_labels+train_labels+dev_labels)\n",
    "# class_mapper.fit(train_labels, train_labels)\n",
    "# class_mapper.fit(train_texts+train_labels, train_labels+train_labels)\n",
    "class_mapper.fit(train_texts+train_labels+train_df['text'].tolist(), \n",
    "                 train_labels+train_labels+train_df[column].tolist())\n",
    "# +train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27b860ea-1a1d-4e87-bdfc-a9b87e08a8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.9038    0.8393    0.8704        56\n",
      "                       1.2 incitement and encouragement of harm     0.9669    0.9213    0.9435       254\n",
      "                                        2.1 descriptive attacks     0.8899    0.9247    0.9070       717\n",
      "                             2.2 aggressive and emotive attacks     0.8784    0.9123    0.8950       673\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.9239    0.9100    0.9169       200\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.9051    0.9137    0.9094       637\n",
      "        3.2 immutable gender differences and gender stereotypes     0.9102    0.8753    0.8924       417\n",
      "                            3.3 backhanded gendered compliments     0.9783    0.7031    0.8182        64\n",
      "             3.4 condescending explanations or unwelcome advice     0.8889    0.6809    0.7711        47\n",
      "                4.1 supporting mistreatment of individual women     0.9315    0.9067    0.9189        75\n",
      "4.2 supporting systemic discrimination against women as a group     0.9621    0.9845    0.9732       258\n",
      "\n",
      "                                                       accuracy                         0.9082      3398\n",
      "                                                      macro avg     0.9217    0.8702    0.8924      3398\n",
      "                                                   weighted avg     0.9090    0.9082    0.9077      3398\n",
      "\n",
      "DEV------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.4545    0.6250    0.5263         8\n",
      "                       1.2 incitement and encouragement of harm     0.6552    0.5278    0.5846        36\n",
      "                                        2.1 descriptive attacks     0.5197    0.6471    0.5764       102\n",
      "                             2.2 aggressive and emotive attacks     0.5049    0.5417    0.5226        96\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.5000    0.3793    0.4314        29\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.6279    0.5934    0.6102        91\n",
      "        3.2 immutable gender differences and gender stereotypes     0.5455    0.5000    0.5217        60\n",
      "                            3.3 backhanded gendered compliments     0.0000    0.0000    0.0000         9\n",
      "             3.4 condescending explanations or unwelcome advice     0.0000    0.0000    0.0000         7\n",
      "                4.1 supporting mistreatment of individual women     0.2857    0.3636    0.3200        11\n",
      "4.2 supporting systemic discrimination against women as a group     0.5556    0.5405    0.5479        37\n",
      "\n",
      "                                                       accuracy                         0.5370       486\n",
      "                                                      macro avg     0.4226    0.4289    0.4219       486\n",
      "                                                   weighted avg     0.5283    0.5370    0.5295       486\n",
      "\n",
      "TEST------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.4286    0.3750    0.4000        16\n",
      "                       1.2 incitement and encouragement of harm     0.7400    0.5068    0.6016        73\n",
      "                                        2.1 descriptive attacks     0.4880    0.5951    0.5363       205\n",
      "                             2.2 aggressive and emotive attacks     0.5022    0.6042    0.5485       192\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.3800    0.3333    0.3551        57\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.6611    0.6538    0.6575       182\n",
      "        3.2 immutable gender differences and gender stereotypes     0.5096    0.4454    0.4753       119\n",
      "                            3.3 backhanded gendered compliments     0.4444    0.2222    0.2963        18\n",
      "             3.4 condescending explanations or unwelcome advice     0.2500    0.0714    0.1111        14\n",
      "                4.1 supporting mistreatment of individual women     0.4286    0.2857    0.3429        21\n",
      "4.2 supporting systemic discrimination against women as a group     0.5625    0.4932    0.5255        73\n",
      "\n",
      "                                                       accuracy                         0.5351       970\n",
      "                                                      macro avg     0.4905    0.4169    0.4409       970\n",
      "                                                   weighted avg     0.5377    0.5351    0.5304       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predict = class_mapper.predict(train_texts)\n",
    "dev_predict = class_mapper.predict(dev_texts)\n",
    "test_predict = class_mapper.predict(test_texts)\n",
    "\n",
    "print(\"TRAIN\"+\"-\"*150)\n",
    "print(classification_report(train_labels, train_predict, digits=4))\n",
    "print(\"DEV\"+\"-\"*150)\n",
    "print(classification_report(dev_labels, dev_predict, digits=4))\n",
    "print(\"TEST\"+\"-\"*150)\n",
    "print(classification_report(test_labels, test_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac63cf00-87b3-4d1e-9621-f4f0b6f09cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abe89f249c34f31927c3dd2f7645402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2032eb35aaf145b38aad72acc6ad4161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48a0376b696433b8537a700ae6c3a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sbert = SentenceTransformer(\"sentence-transformers/nli-mpnet-base-v2\")\n",
    "\n",
    "train_texts_vec = sbert.encode(train_texts+train_df['text'].tolist(), show_progress_bar=True)\n",
    "dev_texts_vec = sbert.encode(dev_texts, show_progress_bar=True)\n",
    "test_texts_vec = sbert.encode(test_texts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b046d90-a23b-4082-8e33-369d5851b33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.8721    0.6696    0.7576       112\n",
      "                       1.2 incitement and encouragement of harm     0.8577    0.8071    0.8316       508\n",
      "                                        2.1 descriptive attacks     0.7277    0.8068    0.7652      1434\n",
      "                             2.2 aggressive and emotive attacks     0.7234    0.7831    0.7521      1346\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.7934    0.6625    0.7221       400\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.7789    0.7771    0.7780      1274\n",
      "        3.2 immutable gender differences and gender stereotypes     0.7601    0.7410    0.7505       834\n",
      "                            3.3 backhanded gendered compliments     0.8652    0.6016    0.7097       128\n",
      "             3.4 condescending explanations or unwelcome advice     0.9459    0.3723    0.5344        94\n",
      "                4.1 supporting mistreatment of individual women     0.8320    0.6933    0.7564       150\n",
      "4.2 supporting systemic discrimination against women as a group     0.8430    0.8430    0.8430       516\n",
      "\n",
      "                                                       accuracy                         0.7681      6796\n",
      "                                                      macro avg     0.8181    0.7052    0.7455      6796\n",
      "                                                   weighted avg     0.7731    0.7681    0.7670      6796\n",
      "\n",
      "DEV------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.4545    0.6250    0.5263         8\n",
      "                       1.2 incitement and encouragement of harm     0.6333    0.5278    0.5758        36\n",
      "                                        2.1 descriptive attacks     0.5397    0.6667    0.5965       102\n",
      "                             2.2 aggressive and emotive attacks     0.5000    0.5312    0.5152        96\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.5000    0.3793    0.4314        29\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.6136    0.5934    0.6034        91\n",
      "        3.2 immutable gender differences and gender stereotypes     0.5455    0.5000    0.5217        60\n",
      "                            3.3 backhanded gendered compliments     0.0000    0.0000    0.0000         9\n",
      "             3.4 condescending explanations or unwelcome advice     0.5000    0.1429    0.2222         7\n",
      "                4.1 supporting mistreatment of individual women     0.3077    0.3636    0.3333        11\n",
      "4.2 supporting systemic discrimination against women as a group     0.5556    0.5405    0.5479        37\n",
      "\n",
      "                                                       accuracy                         0.5412       486\n",
      "                                                      macro avg     0.4682    0.4428    0.4431       486\n",
      "                                                   weighted avg     0.5350    0.5412    0.5338       486\n",
      "\n",
      "TEST------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.5000    0.3750    0.4286        16\n",
      "                       1.2 incitement and encouragement of harm     0.7400    0.5068    0.6016        73\n",
      "                                        2.1 descriptive attacks     0.4844    0.6049    0.5380       205\n",
      "                             2.2 aggressive and emotive attacks     0.4915    0.6042    0.5421       192\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.3878    0.3333    0.3585        57\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.6610    0.6429    0.6518       182\n",
      "        3.2 immutable gender differences and gender stereotypes     0.5098    0.4370    0.4706       119\n",
      "                            3.3 backhanded gendered compliments     0.4444    0.2222    0.2963        18\n",
      "             3.4 condescending explanations or unwelcome advice     0.3333    0.0714    0.1176        14\n",
      "                4.1 supporting mistreatment of individual women     0.5000    0.2857    0.3636        21\n",
      "4.2 supporting systemic discrimination against women as a group     0.5625    0.4932    0.5255        73\n",
      "\n",
      "                                                       accuracy                         0.5340       970\n",
      "                                                      macro avg     0.5104    0.4161    0.4449       970\n",
      "                                                   weighted avg     0.5392    0.5340    0.5290       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(100,100),max_iter=1000)\n",
    "clf=LogisticRegression()\n",
    "clf.fit(train_texts_vec, train_labels+train_labels)\n",
    "\n",
    "train_predict = clf.predict(train_texts_vec)\n",
    "dev_predict = clf.predict(dev_texts_vec)\n",
    "test_predict = clf.predict(test_texts_vec)\n",
    "\n",
    "print(\"TRAIN\"+\"-\"*150)\n",
    "print(classification_report(train_labels+train_labels, train_predict, digits=4))\n",
    "print(\"DEV\"+\"-\"*150)\n",
    "print(classification_report(dev_labels, dev_predict, digits=4))\n",
    "print(\"TEST\"+\"-\"*150)\n",
    "print(classification_report(test_labels, test_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26707f4a-c920-443d-8080-994bb3ceea4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f106f5-ddca-4d0e-9b7c-db43fc95ee87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
