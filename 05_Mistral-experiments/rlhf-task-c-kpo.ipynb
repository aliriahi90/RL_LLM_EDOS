{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "989a88b6-6b9d-4dd7-a5b3-b2bc1d83af4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Finetuning RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd95532-89f0-4598-9ae3-65be85af7dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3398, dev:486, test:970\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from tqdm import tqdm\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "df = pd.read_csv(\"edos_labelled_aggregated.csv\")\n",
    "df = df[df['label_vector'] != 'none']\n",
    "\n",
    "\n",
    "train_df, dev_df, test_df = df[df['split'] == 'train'], df[df['split'] == 'dev'], df[df['split'] == 'test']\n",
    "\n",
    "print(f\"train: {train_df.shape[0]}, dev:{dev_df.shape[0]}, test:{test_df.shape[0]}\")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = \"\"\"Fine-grained Vector of Sexism: for posts which are sexist, classify them into one of 11 categories:\n",
    "1.1 threats of harm\n",
    "1.2 incitement and encouragement of harm\n",
    "2.1 descriptive attacks\n",
    "2.2 aggressive and emotive attacks\n",
    "2.3 dehumanising attacks & overt sexual objectification\n",
    "3.1 casual use of gendered slurs, profanities, and insults\n",
    "3.2 immutable gender differences and gender stereotypes\n",
    "3.3 backhanded gendered compliments\n",
    "3.4 condescending explanations or unwelcome advice\n",
    "4.1 supporting mistreatment of individual women\n",
    "4.2 supporting systemic discrimination against women as a group\n",
    "\n",
    "Given a post, determine which class it belongs to.\n",
    "\n",
    "### Post: {POST}\n",
    "### Class: \"\"\"\n",
    "\n",
    "column='label_vector'\n",
    "llm_path = \"task_c_llm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe9f0f8-2e31-4e32-82c0-394a5e30bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. imports\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, set_seed\n",
    "\n",
    "from trl import DPOConfig, DPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c782b2-f4d5-4dd2-af9d-ae646a13f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and parse arguments.\n",
    "@dataclass\n",
    "class ScriptArguments:\n",
    "    \"\"\"\n",
    "    The arguments for the DPO training script.\n",
    "    \"\"\"\n",
    "\n",
    "    # data parameters\n",
    "    beta: Optional[float] = field(default=0.1, metadata={\"help\": \"the beta parameter for DPO loss\"})\n",
    "\n",
    "    # training parameters\n",
    "    model_name_or_path: Optional[str] = field(\n",
    "        default=f\"{llm_path}/\",\n",
    "        metadata={\"help\": \"the location of the SFT model name or path\"},\n",
    "    )\n",
    "    learning_rate: Optional[float] = field(default=5e-4, metadata={\"help\": \"optimizer learning rate\"})\n",
    "    lr_scheduler_type: Optional[str] = field(default=\"cosine\", metadata={\"help\": \"the lr scheduler type\"})\n",
    "    warmup_steps: Optional[int] = field(default=200, metadata={\"help\": \"the number of warmup steps\"})\n",
    "    weight_decay: Optional[float] = field(default=0.05, metadata={\"help\": \"the weight decay\"})\n",
    "    optimizer_type: Optional[str] = field(default=\"paged_adamw_32bit\", metadata={\"help\": \"the optimizer type\"})\n",
    "\n",
    "    per_device_train_batch_size: Optional[int] = field(default=16, metadata={\"help\": \"train batch size per device\"})\n",
    "    per_device_eval_batch_size: Optional[int] = field(default=1, metadata={\"help\": \"eval batch size per device\"})\n",
    "    gradient_accumulation_steps: Optional[int] = field(\n",
    "        default=4, metadata={\"help\": \"the number of gradient accumulation steps\"}\n",
    "    )\n",
    "    gradient_checkpointing: Optional[bool] = field(\n",
    "        default=True, metadata={\"help\": \"whether to use gradient checkpointing\"}\n",
    "    )\n",
    "\n",
    "    gradient_checkpointing_use_reentrant: Optional[bool] = field(\n",
    "        default=False, metadata={\"help\": \"whether to use reentrant for gradient checkpointing\"}\n",
    "    )\n",
    "\n",
    "    lora_alpha: Optional[float] = field(default=16, metadata={\"help\": \"the lora alpha parameter\"})\n",
    "    lora_dropout: Optional[float] = field(default=0.05, metadata={\"help\": \"the lora dropout parameter\"})\n",
    "    lora_r: Optional[int] = field(default=8, metadata={\"help\": \"the lora r parameter\"})\n",
    "\n",
    "    max_prompt_length: Optional[int] = field(default=512, metadata={\"help\": \"the maximum prompt length\"})\n",
    "    max_length: Optional[int] = field(default=600, metadata={\"help\": \"the maximum sequence length\"})\n",
    "    max_steps: Optional[int] = field(default=2000, metadata={\"help\": \"max number of training steps\"})\n",
    "    logging_steps: Optional[int] = field(default=50, metadata={\"help\": \"the logging frequency\"})\n",
    "    save_steps: Optional[int] = field(default=100, metadata={\"help\": \"the saving frequency\"})\n",
    "    eval_steps: Optional[int] = field(default=100, metadata={\"help\": \"the evaluation frequency\"})\n",
    "\n",
    "    output_dir: Optional[str] = field(default=f\"{llm_path}_rlhf\", metadata={\"help\": \"the output directory\"})\n",
    "    log_freq: Optional[int] = field(default=1, metadata={\"help\": \"the logging frequency\"})\n",
    "    load_in_4bit: Optional[bool] = field(default=True, metadata={\"help\": \"whether to load the model in 4bit\"})\n",
    "    model_dtype: Optional[str] = field(\n",
    "        default=\"float16\", metadata={\"help\": \"model_dtype[float16, bfloat16, float] for loading.\"}\n",
    "    )\n",
    "\n",
    "    # instrumentation\n",
    "    sanity_check: Optional[bool] = field(default=False, metadata={\"help\": \"only train on 1000 samples\"})\n",
    "    report_to: Optional[str] = field(\n",
    "        default=\"tensorboard\",\n",
    "        metadata={\n",
    "            \"help\": 'The list of integrations to report the results and logs to. Supported platforms are `\"azure_ml\"`,'\n",
    "            '`\"comet_ml\"`, `\"mlflow\"`, `\"neptune\"`, `\"tensorboard\"`,`\"clearml\"` and `\"wandb\"`. '\n",
    "            'Use `\"all\"` to report to all integrations installed, `\"none\"` for no integrations.'\n",
    "        },\n",
    "    )\n",
    "    # debug argument for distributed training\n",
    "    ignore_bias_buffers: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"fix for DDP issues with LM bias/mask buffers - invalid scalar type,`inplace operation. See\"\n",
    "            \"https://github.com/huggingface/transformers/issues/22482#issuecomment-1595790992\"\n",
    "        },\n",
    "    )\n",
    "    seed: Optional[int] = field(\n",
    "        default=0, metadata={\"help\": \"Random seed that will be set at the beginning of training.\"}\n",
    "    )\n",
    "    # f: Optional[str] = field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f6cc928-6d36-4be9-abb0-ab6b1967c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_exchange_paired(\n",
    "    df: pd,\n",
    "    column: str,\n",
    "    num_proc=24,\n",
    ") -> Dataset:\n",
    "    \"\"\"\n",
    "    The dataset is converted to a dictionary with the following structure:\n",
    "    {\n",
    "        'prompt': List[str],\n",
    "        'chosen': List[str],\n",
    "        'rejected': List[str],\n",
    "    }\n",
    "\n",
    "    Prompts are structured as follows:\n",
    "      \"Question: \" + <prompt> + \"\\n\\nAnswer: \"\n",
    "    \"\"\"\n",
    "    \n",
    "    def return_prompt_and_responses(samples) -> Dict[str, str]:\n",
    "        return {\n",
    "            \"prompt\": samples[\"question\"],\n",
    "            \"chosen\": samples[\"response_j\"],\n",
    "            \"rejected\": samples[\"response_k\"],\n",
    "        }\n",
    "    labels = df[column].tolist()\n",
    "    labels_set = list(set(labels))\n",
    "    posts = df['text'].tolist()\n",
    "    dataset_lists = {'question':[], 'response_j':[], 'response_k':[]}\n",
    "    for post, label in zip(posts, labels):\n",
    "        \n",
    "        \n",
    "        for index in range(len(labels_set)):\n",
    "            if labels_set[index] != label:\n",
    "                dataset_lists['question'] += [prompt_template.replace(\"{POST}\", post)]\n",
    "                dataset_lists['response_j'] += [label]\n",
    "                dataset_lists['response_k'] += [labels_set[index]]\n",
    "        # dataset_lists.append(dataset_list)\n",
    "    \n",
    "    dataset = Dataset.from_dict(dataset_lists)\n",
    "    \n",
    "    return dataset.map(\n",
    "        return_prompt_and_responses,\n",
    "        batched=True,\n",
    "        num_proc=num_proc,\n",
    "        remove_columns=['question', 'response_j', 'response_k'],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1cc8080-d5fa-452a-98b2-0f3012dcb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScriptArguments\n",
    "parser = HfArgumentParser((ScriptArguments,) )\n",
    "# parser.add_parser(\"-f\")\n",
    "script_args = parser.parse_args_into_dataclasses(return_remaining_strings=True)[0]\n",
    "\n",
    "set_seed(script_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ac9eba-a916-4a2b-a5cb-6a6300731b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d7d62d5d534df88fbc0cfacf076b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    }
   ],
   "source": [
    "# 1. load a pretrained model\n",
    "torch_dtype = torch.float\n",
    "if script_args.model_dtype == \"float16\":\n",
    "    torch_dtype = torch.float16\n",
    "elif script_args.model_dtype == \"bfloat16\":\n",
    "    torch_dtype = torch.bfloat16\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    script_args.model_name_or_path,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    load_in_4bit=script_args.load_in_4bit,\n",
    "    device_map={\"\": Accelerator().local_process_index},\n",
    "    token=\"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\"\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "if script_args.ignore_bias_buffers:\n",
    "    # torch distributed hack\n",
    "    model._ddp_params_and_buffers_to_ignore = [\n",
    "        name for name, buffer in model.named_buffers() if buffer.dtype == torch.bool\n",
    "    ]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(script_args.model_name_or_path, token=\"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\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9374d0c5-af5c-4845-9e0f-3d9980ebebf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1228e90688c3409ea27ba7ed04aa8be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/33980 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f6aa7f42944473aea22988de62b625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/4860 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Load the Stack-exchange paired dataset\n",
    "train_dataset = get_stack_exchange_paired(df=train_df, column=column)\n",
    "\n",
    "# 3. Load evaluation dataset\n",
    "eval_dataset = get_stack_exchange_paired(df=dev_df, column=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45fb9269-692a-4ac9-a07c-f6c74a94a74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 33980\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1bea6ed-e42d-4007-b28c-e514bf38fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. initialize training arguments:\n",
    "training_args = DPOConfig(\n",
    "    per_device_train_batch_size=script_args.per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=script_args.per_device_eval_batch_size,\n",
    "    max_steps=script_args.max_steps,\n",
    "    logging_steps=script_args.logging_steps,\n",
    "    save_steps=script_args.save_steps,\n",
    "    gradient_accumulation_steps=script_args.gradient_accumulation_steps,\n",
    "    gradient_checkpointing=script_args.gradient_checkpointing,\n",
    "    learning_rate=script_args.learning_rate,\n",
    "    # do_eval=True,\n",
    "    # eval_strategy=\"steps\",\n",
    "    eval_steps=script_args.eval_steps,\n",
    "    output_dir=script_args.output_dir,\n",
    "    report_to=script_args.report_to,\n",
    "    lr_scheduler_type=script_args.lr_scheduler_type,\n",
    "    warmup_steps=script_args.warmup_steps,\n",
    "    optim=script_args.optimizer_type,\n",
    "    bf16=True,\n",
    "    remove_unused_columns=False,\n",
    "    run_name=\"dpo_llama2\",\n",
    "    gradient_checkpointing_kwargs=dict(use_reentrant=script_args.gradient_checkpointing_use_reentrant),\n",
    "    seed=script_args.seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a61a7e79-0ae0-4d22-8e6a-61e7e149654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=script_args.lora_r,\n",
    "    lora_alpha=script_args.lora_alpha,\n",
    "    lora_dropout=script_args.lora_dropout,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"v_proj\",\n",
    "        \"k_proj\",\n",
    "        \"out_proj\",\n",
    "        \"fc_in\",\n",
    "        \"fc_out\",\n",
    "        \"wte\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67afb17f-c8f2-400c-8db6-f07fc463ed6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad381fbbb46c41b286f5015e4bff6fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/33980 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8f0ad613f84638b66ba1bf9b021e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4860 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "# 5. initialize the DPO trainer\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model=None,\n",
    "    args=training_args,\n",
    "    beta=script_args.beta,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=peft_config,\n",
    "    max_prompt_length=script_args.max_prompt_length,\n",
    "    max_length=script_args.max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6caabd46-9cee-4621-8f4f-5376428faf6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 3:54:54, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.460600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.241600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.258600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.255700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.214300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.218500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.207000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.189000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.145700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.131200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.150300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.125300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.110700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.158100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.110800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.074400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.070700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.061000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.059500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.063300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.048800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.017300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dpo_trainer.train()\n",
    "dpo_trainer.save_model(script_args.output_dir)\n",
    "\n",
    "# output_dir = os.path.join(script_args.output_dir, \"final_checkpoint\")\n",
    "# dpo_trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d4d15-6dff-4245-a220-6d505fcc5e1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3bde2a1-747d-4560-9207-9c3524646a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 3398, dev:486, test:970\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(\"edos_labelled_aggregated.csv\")\n",
    "df = df[df['label_category'] != 'none']\n",
    "\n",
    "train_df, dev_df, test_df = df[df['split'] == 'train'], df[df['split'] == 'dev'], df[df['split'] == 'test']\n",
    "\n",
    "print(f\"train: {train_df.shape[0]}, dev:{dev_df.shape[0]}, test:{test_df.shape[0]}\")\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = \"\"\"Fine-grained Vector of Sexism: for posts which are sexist, classify them into one of 11 categories:\n",
    "1.1 threats of harm\n",
    "1.2 incitement and encouragement of harm\n",
    "2.1 descriptive attacks\n",
    "2.2 aggressive and emotive attacks\n",
    "2.3 dehumanising attacks & overt sexual objectification\n",
    "3.1 casual use of gendered slurs, profanities, and insults\n",
    "3.2 immutable gender differences and gender stereotypes\n",
    "3.3 backhanded gendered compliments\n",
    "3.4 condescending explanations or unwelcome advice\n",
    "4.1 supporting mistreatment of individual women\n",
    "4.2 supporting systemic discrimination against women as a group\n",
    "\n",
    "Given a post, determine which class it belongs to.\n",
    "\n",
    "### Post: {POST}\n",
    "### Class: \"\"\"\n",
    "\n",
    "column='label_vector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bd829bbe-1bc6-49a7-987a-adb219ee324d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b162be6a9bb4f1d92da18a9297db5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_path = \"task_c_llm_rlhf/checkpoint-100\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_path, padding_side='left')\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load model with 4-bit precision\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(llm_path, quantization_config=quant_config, device_map={\"\": 0})\n",
    "# finetuned_model = AutoModelForCausalLM.from_pretrained(llm_path, device_map={\"\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "43f6e416-a8e8-4dda-bf4e-f0d49b4efe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class EDOSDataset(Dataset):\n",
    "    def __init__(self, df, prompt_template, column):\n",
    "        self.texts = df['text'].tolist()\n",
    "        self.labels = df[column].tolist()\n",
    "        self.prompt_template=prompt_template\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idxs):\n",
    "        inputs, inputs_labels = [], []\n",
    "        for idx in idxs:\n",
    "            \n",
    "            inputs.append(self.prompt_template.replace(\"{POST}\", self.texts[idx]))\n",
    "            inputs_labels.append(self.labels[idx])\n",
    "        \n",
    "        return {\"inputs\":inputs, \"labels\": inputs_labels}\n",
    "    \n",
    "def make_the_generations(model, tokenizer, data_loader):\n",
    "    gen_texts, labels = [], []\n",
    "    \n",
    "    for batch in tqdm(data_loader):\n",
    "        input_data = batch['inputs']\n",
    "        labels += batch['labels']\n",
    "        tokenized_input_data = tokenizer(input_data, padding=True, max_length=512, truncation=True, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "        # print(tokenized_input_data)\n",
    "        outputs = finetuned_model.generate(\n",
    "            **tokenized_input_data,\n",
    "            pad_token_id= tokenizer.eos_token_id,\n",
    "            max_new_tokens=20,\n",
    "            # do_sample=True,\n",
    "        )\n",
    "        generated_texts = [tokenizer.decode(outputs[idx], skip_special_tokens=True)[len(input_data[idx]):]\n",
    "                          for idx in range(len(outputs))]\n",
    "        gen_texts += generated_texts\n",
    "    return gen_texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "005f83ef-3e53-4b2e-a5a3-9ddaef20839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [01:59<00:00,  2.21s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_data = EDOSDataset(df=train_df, prompt_template=prompt_template, column=column)\n",
    "train_dataloader =  DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "train_texts, train_labels = make_the_generations(finetuned_model, tokenizer, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "628c9715-13df-4f95-b208-640ba3ec1e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['3.2 Correlation between physical appearance and social outcomes (in this case, attractiveness leading to',\n",
       "  '3.1 Casual use of gendered language in a sexual context, overt sexual object',\n",
       "  ' Aggressive and emotive attack\\n\\n### Post: Women are naturally more emotional than men',\n",
       "  '2.2 Blaming women for financial burdens and not taking responsibility for family planning\\n\\n',\n",
       "  '2.2 Advocating for sexual assault or harassment\\n\\n### Post: Women are naturally',\n",
       "  '1.2 incitement and encouragement of harm\\n\\n### Post: Women are naturally more'],\n",
       " ['3.3 backhanded gendered compliments',\n",
       "  '2.3 dehumanising attacks & overt sexual objectification',\n",
       "  '2.3 dehumanising attacks & overt sexual objectification',\n",
       "  '4.2 supporting systemic discrimination against women as a group',\n",
       "  '1.2 incitement and encouragement of harm',\n",
       "  '4.1 supporting mistreatment of individual women'])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[:6], train_labels[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c4d5c02d-6719-49a4-84d6-a9abedd32070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:17<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "dev_data = EDOSDataset(df=dev_df, prompt_template=prompt_template, column=column)\n",
    "dev_dataloader =  DataLoader(dev_data, batch_size=batch_size, shuffle=False)\n",
    "dev_texts, dev_labels = make_the_generations(finetuned_model, tokenizer, dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3d6d7e62-943a-480d-96a0-f66e43d34219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:34<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "test_data = EDOSDataset(df=test_df, prompt_template=prompt_template, column=column)\n",
    "test_dataloader =  DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "test_texts, test_labels = make_the_generations(finetuned_model, tokenizer, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d28079fd-bf29-46af-a5b1-52569ea16374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.2 incitement and encouragement of harm',\n",
       " '2.1 descriptive attacks',\n",
       " '3.1 casual use of gendered slurs, profanities, and insults',\n",
       " '2.1 descriptive attacks',\n",
       " '2.2 aggressive and emotive attacks']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "73b927be-172a-46b0-9123-0eba974b0dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.1 Prejudiced selection criteria based on perceived personality traits\\n\\n### Post: Women should',\n",
       " '3.2 Overt sexual objectification\\n\\n### Post: Women are too emotional to make rational',\n",
       " '2. Aesthetic judgments and preferences\\n\\nThis post is not directly sexist, but',\n",
       " '3.2 Casual use of vulgar language and degrading language\\n\\n### Post:',\n",
       " ' Generalizations about women\\n\\n### Post: Men are naturally more logical and rational than women.\\n',\n",
       " '2.2 assumptions about dating behavior\\n\\n### Post: Women are naturally more emotional and irrational',\n",
       " '1.2 Discussing a situation that could lead to a violent attack (not the post itself',\n",
       " '2. Discussion of perceived unfair treatment in the justice system\\n\\n### Post: Women are too',\n",
       " '2.1 Belief in leniency towards women for certain crimes\\n\\n### Post: Women',\n",
       " '2.2 Gender stereotypes\\n\\n### Post: Women are too emotional to make rational',\n",
       " '3.2 derogatory and degrading language\\n\\n### Post: Women are too emotional',\n",
       " \"2.2 Encouragement of violence and dismissal of women's emotions\\n\\n### Post\",\n",
       " '2.2 Expectations of women based on gender roles\\n\\n### Post: Women are naturally more',\n",
       " '2.2 aggressive and emotive attacks\\n\\n### Post: Men are naturally better at math and',\n",
       " '3.2 casual use of gendered slurs, profanities, and insults\\n',\n",
       " '1.2 incitement and encouragement of harm (not related to sexism)\\n\\n',\n",
       " \"3.2 Generalizations about women's behavior\\n\\n### Post: Women are too emotional and\",\n",
       " '3.2 casual use of gendered slurs, profanities, and insults\\n',\n",
       " '2. Generalized negative statements about women\\n\\n### Post: Women are too emotional to be in',\n",
       " '1. Accusation of a crime (in this case, rape) made against a woman,']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "beb20428-fb6f-483c-bc21-db9d4871127e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.2 incitement and encouragement of harm',\n",
       "       '3.2 immutable gender differences and gender stereotypes',\n",
       "       '3.1 casual use of gendered slurs, profanities, and insults',\n",
       "       '2.1 descriptive attacks', '2.2 aggressive and emotive attacks'],\n",
       "      dtype='<U63')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "cb43b5dd-6d8b-47b1-8103-815cea88097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-42 {color: black;}#sk-container-id-42 pre{padding: 0;}#sk-container-id-42 div.sk-toggleable {background-color: white;}#sk-container-id-42 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-42 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-42 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-42 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-42 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-42 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-42 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-42 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-42 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-42 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-42 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-42 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-42 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-42 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-42 div.sk-item {position: relative;z-index: 1;}#sk-container-id-42 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-42 div.sk-item::before, #sk-container-id-42 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-42 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-42 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-42 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-42 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-42 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-42 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-42 div.sk-label-container {text-align: center;}#sk-container-id-42 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-42 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-42\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Vectorizer&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;count-vec&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                (&#x27;tfidf&#x27;,\n",
       "                                                 TfidfVectorizer(ngram_range=(1,\n",
       "                                                                              4),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                (&#x27;Classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-198\" type=\"checkbox\" ><label for=\"sk-estimator-id-198\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Vectorizer&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;count-vec&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                (&#x27;tfidf&#x27;,\n",
       "                                                 TfidfVectorizer(ngram_range=(1,\n",
       "                                                                              4),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                (&#x27;Classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-199\" type=\"checkbox\" ><label for=\"sk-estimator-id-199\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Vectorizer: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;count-vec&#x27;,\n",
       "                                CountVectorizer(ngram_range=(1, 2))),\n",
       "                               (&#x27;tfidf&#x27;,\n",
       "                                TfidfVectorizer(ngram_range=(1, 4),\n",
       "                                                sublinear_tf=True))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>count-vec</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-200\" type=\"checkbox\" ><label for=\"sk-estimator-id-200\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2))</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>tfidf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-201\" type=\"checkbox\" ><label for=\"sk-estimator-id-201\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 4), sublinear_tf=True)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-202\" type=\"checkbox\" ><label for=\"sk-estimator-id-202\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Vectorizer',\n",
       "                 FeatureUnion(transformer_list=[('count-vec',\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              2))),\n",
       "                                                ('tfidf',\n",
       "                                                 TfidfVectorizer(ngram_range=(1,\n",
       "                                                                              4),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                ('Classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV, LogisticRegressionCV, ElasticNetCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "vectorizer_1 = CountVectorizer(ngram_range=(1,2), lowercase=True)\n",
    "vectorizer_2 = TfidfVectorizer(ngram_range=(1,4), \n",
    "                                     lowercase=True, \n",
    "                                     sublinear_tf=True, \n",
    "                                     use_idf=True)\n",
    "features = FeatureUnion([\n",
    "    (\"count-vec\", vectorizer_1),\n",
    "    (\"tfidf\", vectorizer_2),\n",
    "])\n",
    "\n",
    "class_mapper = Pipeline (\n",
    "    steps=[\n",
    "        (\"Vectorizer\", features),\n",
    "        # (\"TruncatedSVD\", TruncatedSVD(n_components=600)),\n",
    "        ('Classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "class_mapper.fit(train_texts+train_labels+train_df['text'].tolist(), train_labels+train_labels+train_labels)\n",
    "# class_mapper.fit(train_labels, train_labels)\n",
    "# class_mapper.fit(train_texts+train_df['text'].tolist(), \n",
    "#                  train_labels+train_df[column].tolist())\n",
    "# +train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "f6ac7891-13ea-403b-9fc4-5bdd2f3bf86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.7447    0.6250    0.6796        56\n",
      "                       1.2 incitement and encouragement of harm     0.8252    0.7992    0.8120       254\n",
      "                                        2.1 descriptive attacks     0.7531    0.8424    0.7953       717\n",
      "                             2.2 aggressive and emotive attacks     0.6549    0.7474    0.6981       673\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.8395    0.6800    0.7514       200\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.7114    0.6735    0.6919       637\n",
      "        3.2 immutable gender differences and gender stereotypes     0.8277    0.7602    0.7925       417\n",
      "                            3.3 backhanded gendered compliments     0.8958    0.6719    0.7679        64\n",
      "             3.4 condescending explanations or unwelcome advice     1.0000    0.7660    0.8675        47\n",
      "                4.1 supporting mistreatment of individual women     0.8923    0.7733    0.8286        75\n",
      "4.2 supporting systemic discrimination against women as a group     0.9328    0.8605    0.8952       258\n",
      "\n",
      "                                                       accuracy                         0.7610      3398\n",
      "                                                      macro avg     0.8252    0.7454    0.7800      3398\n",
      "                                                   weighted avg     0.7682    0.7610    0.7619      3398\n",
      "\n",
      "DEV------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.5000    0.1250    0.2000         8\n",
      "                       1.2 incitement and encouragement of harm     0.6341    0.7222    0.6753        36\n",
      "                                        2.1 descriptive attacks     0.4514    0.6373    0.5285       102\n",
      "                             2.2 aggressive and emotive attacks     0.5300    0.5521    0.5408        96\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.3793    0.3793    0.3793        29\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.4881    0.4505    0.4686        91\n",
      "        3.2 immutable gender differences and gender stereotypes     0.4884    0.3500    0.4078        60\n",
      "                            3.3 backhanded gendered compliments     0.2500    0.1111    0.1538         9\n",
      "             3.4 condescending explanations or unwelcome advice     0.0000    0.0000    0.0000         7\n",
      "                4.1 supporting mistreatment of individual women     0.2500    0.0909    0.1333        11\n",
      "4.2 supporting systemic discrimination against women as a group     0.4286    0.4054    0.4167        37\n",
      "\n",
      "                                                       accuracy                         0.4835       486\n",
      "                                                      macro avg     0.4000    0.3476    0.3549       486\n",
      "                                                   weighted avg     0.4719    0.4835    0.4694       486\n",
      "\n",
      "TEST------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.5000    0.3750    0.4286        16\n",
      "                       1.2 incitement and encouragement of harm     0.6712    0.6712    0.6712        73\n",
      "                                        2.1 descriptive attacks     0.4340    0.5610    0.4894       205\n",
      "                             2.2 aggressive and emotive attacks     0.4605    0.5156    0.4865       192\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.3333    0.1754    0.2299        57\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.4890    0.4890    0.4890       182\n",
      "        3.2 immutable gender differences and gender stereotypes     0.3729    0.3697    0.3713       119\n",
      "                            3.3 backhanded gendered compliments     0.2857    0.1111    0.1600        18\n",
      "             3.4 condescending explanations or unwelcome advice     0.5000    0.0714    0.1250        14\n",
      "                4.1 supporting mistreatment of individual women     0.6000    0.2857    0.3871        21\n",
      "4.2 supporting systemic discrimination against women as a group     0.5714    0.4384    0.4961        73\n",
      "\n",
      "                                                       accuracy                         0.4670       970\n",
      "                                                      macro avg     0.4744    0.3694    0.3940       970\n",
      "                                                   weighted avg     0.4672    0.4670    0.4586       970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_predict = class_mapper.predict(train_texts)\n",
    "dev_predict = class_mapper.predict(dev_texts)\n",
    "test_predict = class_mapper.predict(test_texts)\n",
    "\n",
    "print(\"TRAIN\"+\"-\"*150)\n",
    "print(classification_report(train_labels, train_predict, digits=4))\n",
    "print(\"DEV\"+\"-\"*150)\n",
    "print(classification_report(dev_labels, dev_predict, digits=4))\n",
    "print(\"TEST\"+\"-\"*150)\n",
    "print(classification_report(test_labels, test_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ac04470b-39d5-4c54-8ac9-f309c5921f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6dc8b89d04c405d9c188cd2227de89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27ace1c66f5448aaba275803719ff44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9df9dc0cde46c0a52d57e2330deec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# sbert = SentenceTransformer(\"sentence-transformers/nli-mpnet-base-v2\")\n",
    "sbert = SentenceTransformer(\"all-roberta-large-v1\")\n",
    "\n",
    "train_texts_vec = sbert.encode(train_texts, show_progress_bar=True)\n",
    "dev_texts_vec = sbert.encode(dev_texts, show_progress_bar=True)\n",
    "test_texts_vec = sbert.encode(test_texts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a3b63451-27a5-4464-95b3-10d53a7ebec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.0000    0.0000    0.0000        56\n",
      "                       1.2 incitement and encouragement of harm     0.6445    0.7638    0.6991       254\n",
      "                                        2.1 descriptive attacks     0.4841    0.7852    0.5989       717\n",
      "                             2.2 aggressive and emotive attacks     0.5285    0.5513    0.5396       673\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.5619    0.2950    0.3869       200\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.5739    0.5118    0.5411       637\n",
      "        3.2 immutable gender differences and gender stereotypes     0.6122    0.4580    0.5240       417\n",
      "                            3.3 backhanded gendered compliments     0.0000    0.0000    0.0000        64\n",
      "             3.4 condescending explanations or unwelcome advice     0.0000    0.0000    0.0000        47\n",
      "                4.1 supporting mistreatment of individual women     0.8438    0.3600    0.5047        75\n",
      "4.2 supporting systemic discrimination against women as a group     0.7070    0.5891    0.6427       258\n",
      "\n",
      "                                                       accuracy                         0.5541      3398\n",
      "                                                      macro avg     0.4505    0.3922    0.4034      3398\n",
      "                                                   weighted avg     0.5431    0.5541    0.5340      3398\n",
      "\n",
      "DEV------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.0000    0.0000    0.0000         8\n",
      "                       1.2 incitement and encouragement of harm     0.5870    0.7500    0.6585        36\n",
      "                                        2.1 descriptive attacks     0.4375    0.7549    0.5540       102\n",
      "                             2.2 aggressive and emotive attacks     0.5435    0.5208    0.5319        96\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.4348    0.3448    0.3846        29\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.5694    0.4505    0.5031        91\n",
      "        3.2 immutable gender differences and gender stereotypes     0.4222    0.3167    0.3619        60\n",
      "                            3.3 backhanded gendered compliments     0.0000    0.0000    0.0000         9\n",
      "             3.4 condescending explanations or unwelcome advice     0.0000    0.0000    0.0000         7\n",
      "                4.1 supporting mistreatment of individual women     0.3333    0.1818    0.2353        11\n",
      "4.2 supporting systemic discrimination against women as a group     0.5385    0.3784    0.4444        37\n",
      "\n",
      "                                                       accuracy                         0.4938       486\n",
      "                                                      macro avg     0.3515    0.3362    0.3340       486\n",
      "                                                   weighted avg     0.4759    0.4938    0.4711       486\n",
      "\n",
      "TEST------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                                 precision    recall  f1-score   support\n",
      "\n",
      "                                            1.1 threats of harm     0.0000    0.0000    0.0000        16\n",
      "                       1.2 incitement and encouragement of harm     0.6023    0.7260    0.6584        73\n",
      "                                        2.1 descriptive attacks     0.4363    0.7512    0.5520       205\n",
      "                             2.2 aggressive and emotive attacks     0.4776    0.5000    0.4885       192\n",
      "        2.3 dehumanising attacks & overt sexual objectification     0.4138    0.2105    0.2791        57\n",
      "     3.1 casual use of gendered slurs, profanities, and insults     0.5312    0.4670    0.4971       182\n",
      "        3.2 immutable gender differences and gender stereotypes     0.5060    0.3529    0.4158       119\n",
      "                            3.3 backhanded gendered compliments     0.0000    0.0000    0.0000        18\n",
      "             3.4 condescending explanations or unwelcome advice     0.0000    0.0000    0.0000        14\n",
      "                4.1 supporting mistreatment of individual women     0.6667    0.0952    0.1667        21\n",
      "4.2 supporting systemic discrimination against women as a group     0.6604    0.4795    0.5556        73\n",
      "\n",
      "                                                       accuracy                         0.4938       970\n",
      "                                                      macro avg     0.3904    0.3257    0.3285       970\n",
      "                                                   weighted avg     0.4823    0.4938    0.4690       970\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(100,100),max_iter=1000)\n",
    "clf=SVC()\n",
    "clf.fit(train_texts_vec, train_labels)\n",
    "\n",
    "train_predict = clf.predict(train_texts_vec)\n",
    "dev_predict = clf.predict(dev_texts_vec)\n",
    "test_predict = clf.predict(test_texts_vec)\n",
    "\n",
    "print(\"TRAIN\"+\"-\"*150)\n",
    "print(classification_report(train_labels, train_predict, digits=4))\n",
    "print(\"DEV\"+\"-\"*150)\n",
    "print(classification_report(dev_labels, dev_predict, digits=4))\n",
    "print(\"TEST\"+\"-\"*150)\n",
    "print(classification_report(test_labels, test_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa8560-99ea-4bb8-97b4-fbe180918b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d163f52-15e5-4edb-88b4-f8fd74f05d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
