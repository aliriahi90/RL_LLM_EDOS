{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "989a88b6-6b9d-4dd7-a5b3-b2bc1d83af4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Finetuning RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cd95532-89f0-4598-9ae3-65be85af7dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 14000, dev:2000, test:4000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(\"edos_labelled_aggregated.csv\")\n",
    "\n",
    "train_df, dev_df, test_df = df[df['split'] == 'train'], df[df['split'] == 'dev'], df[df['split'] == 'test']\n",
    "\n",
    "print(f\"train: {train_df.shape[0]}, dev:{dev_df.shape[0]}, test:{test_df.shape[0]}\")\n",
    "\n",
    "prompt_template = \"\"\"Binary Sexism Detection: A two-class (or binary) classification where systems have to predict whether a post is sexist or not sexist.\n",
    "\n",
    "Given a post determine the post is belong to sexist or not sexist class.\n",
    "\n",
    "### Post: {POST}\n",
    "### Class: \"\"\"\n",
    "\n",
    "column='label_sexist'\n",
    "\n",
    "llm_path = \"task_a_llm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe9f0f8-2e31-4e32-82c0-394a5e30bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. imports\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser, set_seed\n",
    "\n",
    "from trl import DPOConfig, DPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c782b2-f4d5-4dd2-af9d-ae646a13f532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and parse arguments.\n",
    "@dataclass\n",
    "class ScriptArguments:\n",
    "    \"\"\"\n",
    "    The arguments for the DPO training script.\n",
    "    \"\"\"\n",
    "\n",
    "    # data parameters\n",
    "    beta: Optional[float] = field(default=0.1, metadata={\"help\": \"the beta parameter for DPO loss\"})\n",
    "\n",
    "    # training parameters\n",
    "    model_name_or_path: Optional[str] = field(\n",
    "        default=f\"{llm_path}/\",\n",
    "        metadata={\"help\": \"the location of the SFT model name or path\"},\n",
    "    )\n",
    "    learning_rate: Optional[float] = field(default=5e-4, metadata={\"help\": \"optimizer learning rate\"})\n",
    "    lr_scheduler_type: Optional[str] = field(default=\"cosine\", metadata={\"help\": \"the lr scheduler type\"})\n",
    "    warmup_steps: Optional[int] = field(default=200, metadata={\"help\": \"the number of warmup steps\"})\n",
    "    weight_decay: Optional[float] = field(default=0.05, metadata={\"help\": \"the weight decay\"})\n",
    "    optimizer_type: Optional[str] = field(default=\"paged_adamw_32bit\", metadata={\"help\": \"the optimizer type\"})\n",
    "\n",
    "    per_device_train_batch_size: Optional[int] = field(default=16, metadata={\"help\": \"train batch size per device\"})\n",
    "    per_device_eval_batch_size: Optional[int] = field(default=1, metadata={\"help\": \"eval batch size per device\"})\n",
    "    gradient_accumulation_steps: Optional[int] = field(\n",
    "        default=4, metadata={\"help\": \"the number of gradient accumulation steps\"}\n",
    "    )\n",
    "    gradient_checkpointing: Optional[bool] = field(\n",
    "        default=True, metadata={\"help\": \"whether to use gradient checkpointing\"}\n",
    "    )\n",
    "\n",
    "    gradient_checkpointing_use_reentrant: Optional[bool] = field(\n",
    "        default=False, metadata={\"help\": \"whether to use reentrant for gradient checkpointing\"}\n",
    "    )\n",
    "\n",
    "    lora_alpha: Optional[float] = field(default=16, metadata={\"help\": \"the lora alpha parameter\"})\n",
    "    lora_dropout: Optional[float] = field(default=0.05, metadata={\"help\": \"the lora dropout parameter\"})\n",
    "    lora_r: Optional[int] = field(default=8, metadata={\"help\": \"the lora r parameter\"})\n",
    "\n",
    "    max_prompt_length: Optional[int] = field(default=512, metadata={\"help\": \"the maximum prompt length\"})\n",
    "    max_length: Optional[int] = field(default=600, metadata={\"help\": \"the maximum sequence length\"})\n",
    "    max_steps: Optional[int] = field(default=2000, metadata={\"help\": \"max number of training steps\"})\n",
    "    logging_steps: Optional[int] = field(default=100, metadata={\"help\": \"the logging frequency\"})\n",
    "    save_steps: Optional[int] = field(default=100, metadata={\"help\": \"the saving frequency\"})\n",
    "    eval_steps: Optional[int] = field(default=100, metadata={\"help\": \"the evaluation frequency\"})\n",
    "\n",
    "    output_dir: Optional[str] = field(default=f\"{llm_path}_rlhf\", metadata={\"help\": \"the output directory\"})\n",
    "    log_freq: Optional[int] = field(default=1, metadata={\"help\": \"the logging frequency\"})\n",
    "    load_in_4bit: Optional[bool] = field(default=True, metadata={\"help\": \"whether to load the model in 4bit\"})\n",
    "    model_dtype: Optional[str] = field(\n",
    "        default=\"float16\", metadata={\"help\": \"model_dtype[float16, bfloat16, float] for loading.\"}\n",
    "    )\n",
    "\n",
    "    # instrumentation\n",
    "    sanity_check: Optional[bool] = field(default=False, metadata={\"help\": \"only train on 1000 samples\"})\n",
    "    report_to: Optional[str] = field(\n",
    "        default=\"tensorboard\",\n",
    "        metadata={\n",
    "            \"help\": 'The list of integrations to report the results and logs to. Supported platforms are `\"azure_ml\"`,'\n",
    "            '`\"comet_ml\"`, `\"mlflow\"`, `\"neptune\"`, `\"tensorboard\"`,`\"clearml\"` and `\"wandb\"`. '\n",
    "            'Use `\"all\"` to report to all integrations installed, `\"none\"` for no integrations.'\n",
    "        },\n",
    "    )\n",
    "    # debug argument for distributed training\n",
    "    ignore_bias_buffers: Optional[bool] = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": \"fix for DDP issues with LM bias/mask buffers - invalid scalar type,`inplace operation. See\"\n",
    "            \"https://github.com/huggingface/transformers/issues/22482#issuecomment-1595790992\"\n",
    "        },\n",
    "    )\n",
    "    seed: Optional[int] = field(\n",
    "        default=0, metadata={\"help\": \"Random seed that will be set at the beginning of training.\"}\n",
    "    )\n",
    "    # f: Optional[str] = field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f6cc928-6d36-4be9-abb0-ab6b1967c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stack_exchange_paired(\n",
    "    df: pd,\n",
    "    column: str,\n",
    "    num_proc=24,\n",
    ") -> Dataset:\n",
    "    \"\"\"\n",
    "    The dataset is converted to a dictionary with the following structure:\n",
    "    {\n",
    "        'prompt': List[str],\n",
    "        'chosen': List[str],\n",
    "        'rejected': List[str],\n",
    "    }\n",
    "\n",
    "    Prompts are structured as follows:\n",
    "      \"Question: \" + <prompt> + \"\\n\\nAnswer: \"\n",
    "    \"\"\"\n",
    "    \n",
    "    def return_prompt_and_responses(samples) -> Dict[str, str]:\n",
    "        return {\n",
    "            \"prompt\": samples[\"question\"],\n",
    "            \"chosen\": samples[\"response_j\"],\n",
    "            \"rejected\": samples[\"response_k\"],\n",
    "        }\n",
    "    labels = df[column].tolist()\n",
    "    labels_set = list(set(labels))\n",
    "    posts = df['text'].tolist()\n",
    "    dataset_lists = {'question':[], 'response_j':[], 'response_k':[]}\n",
    "    for post, label in zip(posts, labels):\n",
    "        \n",
    "        \n",
    "        for index in range(len(labels_set)):\n",
    "            if labels_set[index] != label:\n",
    "                dataset_lists['question'] += [prompt_template.replace(\"{POST}\", post)]\n",
    "                dataset_lists['response_j'] += [label]\n",
    "                dataset_lists['response_k'] += [labels_set[index]]\n",
    "        # dataset_lists.append(dataset_list)\n",
    "    \n",
    "    dataset = Dataset.from_dict(dataset_lists)\n",
    "    \n",
    "    return dataset.map(\n",
    "        return_prompt_and_responses,\n",
    "        batched=True,\n",
    "        num_proc=num_proc,\n",
    "        remove_columns=['question', 'response_j', 'response_k'],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1cc8080-d5fa-452a-98b2-0f3012dcb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ScriptArguments\n",
    "parser = HfArgumentParser((ScriptArguments,) )\n",
    "# parser.add_parser(\"-f\")\n",
    "script_args = parser.parse_args_into_dataclasses(return_remaining_strings=True)[0]\n",
    "\n",
    "set_seed(script_args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ac9eba-a916-4a2b-a5cb-6a6300731b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa4d50155fc4959a00040f8385bc79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. load a pretrained model\n",
    "torch_dtype = torch.float\n",
    "if script_args.model_dtype == \"float16\":\n",
    "    torch_dtype = torch.float16\n",
    "elif script_args.model_dtype == \"bfloat16\":\n",
    "    torch_dtype = torch.bfloat16\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    script_args.model_name_or_path,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    load_in_4bit=script_args.load_in_4bit,\n",
    "    device_map={\"\": Accelerator().local_process_index},\n",
    "    token=\"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\"\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "if script_args.ignore_bias_buffers:\n",
    "    # torch distributed hack\n",
    "    model._ddp_params_and_buffers_to_ignore = [\n",
    "        name for name, buffer in model.named_buffers() if buffer.dtype == torch.bool\n",
    "    ]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(script_args.model_name_or_path, token=\"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\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9374d0c5-af5c-4845-9e0f-3d9980ebebf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c489affda246afbbd88b06903dd572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/14000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1282934a75c7419bb3e058016ac3cc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Load the Stack-exchange paired dataset\n",
    "train_dataset = get_stack_exchange_paired(df=train_df, column=column)\n",
    "\n",
    "# 3. Load evaluation dataset\n",
    "eval_dataset = get_stack_exchange_paired(df=dev_df, column=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45fb9269-692a-4ac9-a07c-f6c74a94a74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 14000\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1bea6ed-e42d-4007-b28c-e514bf38fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. initialize training arguments:\n",
    "training_args = DPOConfig(\n",
    "    per_device_train_batch_size=script_args.per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=script_args.per_device_eval_batch_size,\n",
    "    max_steps=script_args.max_steps,\n",
    "    logging_steps=script_args.logging_steps,\n",
    "    save_steps=script_args.save_steps,\n",
    "    gradient_accumulation_steps=script_args.gradient_accumulation_steps,\n",
    "    gradient_checkpointing=script_args.gradient_checkpointing,\n",
    "    learning_rate=script_args.learning_rate,\n",
    "    # do_eval=True,\n",
    "    # eval_strategy=\"steps\",\n",
    "    eval_steps=script_args.eval_steps,\n",
    "    output_dir=script_args.output_dir,\n",
    "    report_to=script_args.report_to,\n",
    "    lr_scheduler_type=script_args.lr_scheduler_type,\n",
    "    warmup_steps=script_args.warmup_steps,\n",
    "    optim=script_args.optimizer_type,\n",
    "    bf16=True,\n",
    "    remove_unused_columns=False,\n",
    "    run_name=\"dpo_llama2\",\n",
    "    gradient_checkpointing_kwargs=dict(use_reentrant=script_args.gradient_checkpointing_use_reentrant),\n",
    "    seed=script_args.seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a61a7e79-0ae0-4d22-8e6a-61e7e149654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=script_args.lora_r,\n",
    "    lora_alpha=script_args.lora_alpha,\n",
    "    lora_dropout=script_args.lora_dropout,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"v_proj\",\n",
    "        \"k_proj\",\n",
    "        \"out_proj\",\n",
    "        \"fc_in\",\n",
    "        \"fc_out\",\n",
    "        \"wte\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67afb17f-c8f2-400c-8db6-f07fc463ed6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_prompt_length, max_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in DPOTrainer, please use the DPOConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/trl/trainer/dpo_trainer.py:358: UserWarning: You passed `max_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/trl/trainer/dpo_trainer.py:371: UserWarning: You passed `max_prompt_length` to the DPOTrainer, the value you passed will override the one in the `DPOConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2236078f514f25a1cd957fa3166748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024c57cb1552489db7c6adbc4a3cec37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "# 5. initialize the DPO trainer\n",
    "dpo_trainer = DPOTrainer(\n",
    "    model,\n",
    "    ref_model=None,\n",
    "    args=training_args,\n",
    "    beta=script_args.beta,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=peft_config,\n",
    "    max_prompt_length=script_args.max_prompt_length,\n",
    "    max_length=script_args.max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6caabd46-9cee-4621-8f4f-5376428faf6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 2:10:20, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.278200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.268000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.292700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.244900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.577300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.570800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.446800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.789300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.636900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.605600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.566200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.568200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.551600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.562300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.560600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.560400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-666f1531-087f7a6b3b54ca8d2877e942;f1cc9a13-937d-4772-85ae-da062fca6831)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-666f183f-472e9e620bf2acce20695d7a;bf4a7edc-cbe3-4b95-abdc-0acfd37c4412)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-666f1b4c-0bcd43ff0777412d10717035;fbf921de-0ca9-4313-a5dc-3b238cd4546f)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-666f1e5e-71fb049a1329c1575a309eb0;f3f26a00-d23f-4bc6-be20-23cffe7e733c)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-666f216e-00d186fd28755f541b96a0ce;352cb33e-bb5e-48cc-9c5e-8b65050cedbd)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-666f247a-71f585646189b51929a1a91a;f87e0919-fb08-452d-8160-0e068617245f)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-666f2787-7b7d6faf6405bc5052346198;aabd589b-e1d2-4028-8189-4cd51a4d13e2)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-666f2a96-2d8f5f56589629aa79097dd7;9bbc949a-c065-4996-b018-4b8cac4df6c4)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-666f2da4-1dc3b0666e5dd36817006deb;bb3816cd-1abe-4f3a-80f6-e8a83a903e59)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-666f30b2-1324fd7e54d5050b2ddc8e6b;8e68fd45-874c-4104-8c4b-7a6889363523)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-666f30b4-2bd74b1721d6d58572f95e0f;2b3f7ef1-85bc-40e0-b10b-2a91464ea759)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-v0.1/resolve/main/config.json.\n",
      "Access to model mistralai/Mistral-7B-v0.1 is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in mistralai/Mistral-7B-v0.1.\n",
      "  warnings.warn(\n",
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in mistralai/Mistral-7B-v0.1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dpo_trainer.train()\n",
    "dpo_trainer.save_model(script_args.output_dir)\n",
    "\n",
    "# output_dir = os.path.join(script_args.output_dir, \"final_checkpoint\")\n",
    "# dpo_trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d4d15-6dff-4245-a220-6d505fcc5e1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3bde2a1-747d-4560-9207-9c3524646a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 14000, dev:2000, test:4000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(\"edos_labelled_aggregated.csv\")\n",
    "\n",
    "train_df, dev_df, test_df = df[df['split'] == 'train'], df[df['split'] == 'dev'], df[df['split'] == 'test']\n",
    "\n",
    "print(f\"train: {train_df.shape[0]}, dev:{dev_df.shape[0]}, test:{test_df.shape[0]}\")\n",
    "\n",
    "prompt_template = \"\"\"Binary Sexism Detection: A two-class (or binary) classification where systems have to predict whether a post is sexist or not sexist.\n",
    "\n",
    "Given a post determine the post is belong to sexist or not sexist class. \n",
    "\n",
    "### Post: {POST}\n",
    "### Class: \"\"\"\n",
    "\n",
    "column='label_sexist'\n",
    "\n",
    "llm_path = \"task_a_llm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd829bbe-1bc6-49a7-987a-adb219ee324d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ad4f566c8d4bb9bdd4c85dd52c271f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_path = \"task_a_llm_rlhf/checkpoint-200\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_path, padding_side='left')\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Load model with 4-bit precision\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(llm_path, quantization_config=quant_config, device_map={\"\": 0})\n",
    "# finetuned_model = AutoModelForCausalLM.from_pretrained(llm_path, device_map={\"\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f6e416-a8e8-4dda-bf4e-f0d49b4efe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class EDOSDataset(Dataset):\n",
    "    def __init__(self, df, prompt_template, column):\n",
    "        self.texts = df['text'].tolist()\n",
    "        self.labels = df[column].tolist()\n",
    "        self.prompt_template=prompt_template\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idxs):\n",
    "        inputs, inputs_labels = [], []\n",
    "        for idx in idxs:\n",
    "            \n",
    "            inputs.append(self.prompt_template.replace(\"{POST}\", self.texts[idx]))\n",
    "            inputs_labels.append(self.labels[idx])\n",
    "        \n",
    "        return {\"inputs\":inputs, \"labels\": inputs_labels}\n",
    "    \n",
    "def make_the_generations(model, tokenizer, data_loader):\n",
    "    gen_texts, labels = [], []\n",
    "    \n",
    "    for batch in tqdm(data_loader):\n",
    "        input_data = batch['inputs']\n",
    "        labels += batch['labels']\n",
    "        tokenized_input_data = tokenizer(input_data, padding=True, max_length=512, \n",
    "                                         truncation=True, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "        # print(tokenized_input_data)\n",
    "        outputs = finetuned_model.generate(\n",
    "            **tokenized_input_data,\n",
    "            pad_token_id= tokenizer.eos_token_id,\n",
    "            max_new_tokens=15,\n",
    "            # do_sample=True\n",
    "        )\n",
    "        generated_texts = [tokenizer.decode(outputs[idx], skip_special_tokens=True)[len(input_data[idx]):]\n",
    "                          for idx in range(len(outputs))]\n",
    "        gen_texts += generated_texts\n",
    "    return gen_texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005f83ef-3e53-4b2e-a5a3-9ddaef20839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [05:08<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_data = EDOSDataset(df=train_df, prompt_template=prompt_template, column=column)\n",
    "train_dataloader =  DataLoader(train_data, batch_size=batch_size, shuffle=False)\n",
    "train_texts, train_labels = make_the_generations(finetuned_model, tokenizer, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628c9715-13df-4f95-b208-640ba3ec1e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\" not sexist\\n\\n### Post: I'm not sure if this\",\n",
       "  \" not sexist\\n\\n### Post: I'm not sure if this\",\n",
       "  ' not sexist\\n\\n### Post: man?\\n### Class: not',\n",
       "  \" not sexist\\n\\n### Post: I'm not sure if this\",\n",
       "  '1. Not very nice, but not sexist.\\n\\n### Post',\n",
       "  '1. Not sure if this is a troll or not. \\n'],\n",
       " ['not sexist',\n",
       "  'not sexist',\n",
       "  'not sexist',\n",
       "  'not sexist',\n",
       "  'sexist',\n",
       "  'not sexist'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[:6], train_labels[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d5c02d-6719-49a4-84d6-a9abedd32070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:44<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "dev_data = EDOSDataset(df=dev_df, prompt_template=prompt_template, column=column)\n",
    "dev_dataloader =  DataLoader(dev_data, batch_size=batch_size, shuffle=False)\n",
    "dev_texts, dev_labels = make_the_generations(finetuned_model, tokenizer, dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d6d7e62-943a-480d-96a0-f66e43d34219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:30<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "test_data = EDOSDataset(df=test_df, prompt_template=prompt_template, column=column)\n",
    "test_dataloader =  DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "test_texts, test_labels = make_the_generations(finetuned_model, tokenizer, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28079fd-bf29-46af-a5b1-52569ea16374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not sexist', 'sexist', 'not sexist', 'not sexist', 'sexist']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73b927be-172a-46b0-9123-0eba974b0dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' not sexist\\n\\n### Post: I fucked a girl 14',\n",
       " \" not sexist\\n\\n### Post: I'm not sure if I\",\n",
       " \" not sexist\\n\\n### Post: [USER] I'm not\",\n",
       " \" not sexist\\n\\n### Post:\\n\\n> I'm not\",\n",
       " \" not sexist\\n\\n### Post: I'm not sure if this\",\n",
       " '100% not-a-Muslim\\n\\n### Post:',\n",
       " \" not sexist\\n\\n### Post: I'm not sure what this\",\n",
       " \" not sexist\\n\\n### Post: I'm not a fan of\",\n",
       " ' not sexist\\n\\n### Post: I’m not sure if this',\n",
       " \" not sexist\\n\\n### Post: I'm not a racist,\",\n",
       " '1. Not women are not playing games because it is more exciting. ',\n",
       " \" not sexist\\n\\n### Post: I'm not sure if this\",\n",
       " \" not sexist\\n\\n### Post: I'm not sure if this\",\n",
       " \" not sexist\\n\\n### Post: I've had words with #\",\n",
       " \" not sexist\\n\\n### Post: I'm not sure if this\",\n",
       " \" not sexist\\n\\n### Post: I'm not sure if this\",\n",
       " \"1. Misogynistic\\n\\n### Post: I'm not\",\n",
       " \"0\\n\\n### Post: I'm not sure if this is a\",\n",
       " ' not sexist\\n\\n### Post: I’m not sure if this',\n",
       " \" not sexist\\n\\n### Post: I'm not a fan of\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_texts[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "beb20428-fb6f-483c-bc21-db9d4871127e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not sexist', 'sexist', 'not sexist', 'not sexist', 'not sexist'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb43b5dd-6d8b-47b1-8103-815cea88097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/babaeih/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Vectorizer&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;count-vec&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              3))),\n",
       "                                                (&#x27;tfidf&#x27;,\n",
       "                                                 TfidfVectorizer(ngram_range=(1,\n",
       "                                                                              5),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                (&#x27;Classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Vectorizer&#x27;,\n",
       "                 FeatureUnion(transformer_list=[(&#x27;count-vec&#x27;,\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              3))),\n",
       "                                                (&#x27;tfidf&#x27;,\n",
       "                                                 TfidfVectorizer(ngram_range=(1,\n",
       "                                                                              5),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                (&#x27;Classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Vectorizer: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;count-vec&#x27;,\n",
       "                                CountVectorizer(ngram_range=(1, 3))),\n",
       "                               (&#x27;tfidf&#x27;,\n",
       "                                TfidfVectorizer(ngram_range=(1, 5),\n",
       "                                                sublinear_tf=True))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>count-vec</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 3))</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>tfidf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 5), sublinear_tf=True)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Vectorizer',\n",
       "                 FeatureUnion(transformer_list=[('count-vec',\n",
       "                                                 CountVectorizer(ngram_range=(1,\n",
       "                                                                              3))),\n",
       "                                                ('tfidf',\n",
       "                                                 TfidfVectorizer(ngram_range=(1,\n",
       "                                                                              5),\n",
       "                                                                 sublinear_tf=True))])),\n",
       "                ('Classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV, LogisticRegressionCV, ElasticNetCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "vectorizer_1 = CountVectorizer(ngram_range=(1,3), lowercase=True)\n",
    "vectorizer_2 = TfidfVectorizer( ngram_range=(1,5), \n",
    "                                     lowercase=True, \n",
    "                                     sublinear_tf=True, \n",
    "                                     use_idf=True)\n",
    "features = FeatureUnion([\n",
    "    (\"count-vec\", vectorizer_1),\n",
    "    (\"tfidf\", vectorizer_2),\n",
    "])\n",
    "\n",
    "class_mapper = Pipeline (\n",
    "    steps=[\n",
    "        (\"Vectorizer\", features),\n",
    "        # (\"TruncatedSVD\", TruncatedSVD(n_components=600)),\n",
    "        ('Classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# class_mapper.fit(train_texts+train_labels+dev_texts, train_labels+train_labels+dev_labels)\n",
    "# class_mapper.fit(train_labels, train_labels)\n",
    "class_mapper.fit(train_texts+train_labels+train_df['text'].tolist(), \n",
    "                 train_labels+train_labels+train_df[column].tolist())\n",
    "# +train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6ac7891-13ea-403b-9fc4-5bdd2f3bf86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist     0.9423    0.9670    0.9545     10602\n",
      "      sexist     0.8878    0.8152    0.8500      3398\n",
      "\n",
      "    accuracy                         0.9301     14000\n",
      "   macro avg     0.9150    0.8911    0.9022     14000\n",
      "weighted avg     0.9291    0.9301    0.9291     14000\n",
      "\n",
      "DEV------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist     0.9114    0.9518    0.9312      1514\n",
      "      sexist     0.8258    0.7119    0.7646       486\n",
      "\n",
      "    accuracy                         0.8935      2000\n",
      "   macro avg     0.8686    0.8319    0.8479      2000\n",
      "weighted avg     0.8906    0.8935    0.8907      2000\n",
      "\n",
      "TEST------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist     0.9082    0.9439    0.9257      3030\n",
      "      sexist     0.8002    0.7021    0.7479       970\n",
      "\n",
      "    accuracy                         0.8852      4000\n",
      "   macro avg     0.8542    0.8230    0.8368      4000\n",
      "weighted avg     0.8820    0.8852    0.8826      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predict = class_mapper.predict(train_texts)\n",
    "dev_predict = class_mapper.predict(dev_texts)\n",
    "test_predict = class_mapper.predict(test_texts)\n",
    "\n",
    "print(\"TRAIN\"+\"-\"*150)\n",
    "print(classification_report(train_labels, train_predict, digits=4))\n",
    "print(\"DEV\"+\"-\"*150)\n",
    "print(classification_report(dev_labels, dev_predict, digits=4))\n",
    "print(\"TEST\"+\"-\"*150)\n",
    "print(classification_report(test_labels, test_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac04470b-39d5-4c54-8ac9-f309c5921f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19dc46d2d51493c8975fc55fbd72e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c37fb4b999841518b747f635d73ef94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dece5b0554249b99d6e3fe36c0ef17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sbert = SentenceTransformer(\"sentence-transformers/nli-mpnet-base-v2\")\n",
    "# sbert = SentenceTransformer(\"all-roberta-large-v1\")\n",
    "\n",
    "train_texts_vec = sbert.encode(train_texts+dev_texts+train_labels, show_progress_bar=True)\n",
    "dev_texts_vec = sbert.encode(dev_texts, show_progress_bar=True)\n",
    "test_texts_vec = sbert.encode(test_texts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3b63451-27a5-4464-95b3-10d53a7ebec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist     0.9606    0.9808    0.9706     22718\n",
      "      sexist     0.9359    0.8745    0.9042      7282\n",
      "\n",
      "    accuracy                         0.9550     30000\n",
      "   macro avg     0.9483    0.9276    0.9374     30000\n",
      "weighted avg     0.9546    0.9550    0.9545     30000\n",
      "\n",
      "DEV------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist     0.9230    0.9657    0.9438      1514\n",
      "      sexist     0.8750    0.7490    0.8071       486\n",
      "\n",
      "    accuracy                         0.9130      2000\n",
      "   macro avg     0.8990    0.8573    0.8755      2000\n",
      "weighted avg     0.9113    0.9130    0.9106      2000\n",
      "\n",
      "TEST------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  not sexist     0.9079    0.9498    0.9284      3030\n",
      "      sexist     0.8169    0.6990    0.7533       970\n",
      "\n",
      "    accuracy                         0.8890      4000\n",
      "   macro avg     0.8624    0.8244    0.8409      4000\n",
      "weighted avg     0.8858    0.8890    0.8859      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifierCV\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(50,50,50),max_iter=300, verbose=True)\n",
    "clf=SVC()\n",
    "# # clf = XGBClassifier(tree_method=\"hist\")\n",
    "# # y = train_labels+dev_labels+train_labels\n",
    "\n",
    "clf.fit(train_texts_vec, train_labels+dev_labels+train_labels)\n",
    "\n",
    "train_predict = clf.predict(train_texts_vec)\n",
    "dev_predict = clf.predict(dev_texts_vec)\n",
    "test_predict = clf.predict(test_texts_vec)\n",
    "\n",
    "print(\"TRAIN\"+\"-\"*150)\n",
    "print(classification_report(train_labels+dev_labels+train_labels, train_predict, digits=4))\n",
    "print(\"DEV\"+\"-\"*150)\n",
    "print(classification_report(dev_labels, dev_predict, digits=4))\n",
    "print(\"TEST\"+\"-\"*150)\n",
    "print(classification_report(test_labels, test_predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3744d4f4-4666-40bf-984d-09a651fc0f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
